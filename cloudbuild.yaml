steps:
  - name: gcr.io/cloud-builders/gcloud
    args:
      - '-c'
      - |
        set -e
        if gcloud composer environments describe ${_ENV_NAME} \
          --location ${_REGION} >/dev/null 2>&1; then
          echo "Composer environment already exists"
        else
          echo "Creating Composer environment..."
          gcloud composer environments create ${_ENV_NAME} \
            --location ${_REGION} \
            --image-version ${_IMAGE_VERSION} \
            --service-account ${_SERVICE_ACCOUNT} \
            --environment-size small
        fi
    id: create-composer-env
    entrypoint: bash
  - name: gcr.io/cloud-builders/gcloud
    args:
      - '-c'
      - >
        set -e

        # Note: We use $$ for bash variables to avoid Cloud Build substitution
        errors

        FULL_PATH=$(gcloud composer environments describe ${_ENV_NAME} \
          --location ${_REGION} \
          --format="value(config.dagGcsPrefix)")

        # Strip 'gs://' from start and '/dags' from end

        TEMP_BUCKET=$${FULL_PATH#gs://}

        CLEAN_BUCKET=$${TEMP_BUCKET%/dags}


        echo "$$CLEAN_BUCKET" > /workspace/bucket_name.txt

        echo "Identified Bucket: $$CLEAN_BUCKET"
    id: fetch-composer-bucket
    entrypoint: bash
  - name: gcr.io/cloud-builders/gsutil
    args:
      - '-c'
      - |
        TARGET_BUCKET=$(cat /workspace/bucket_name.txt)
        gsutil -m rsync -r -d airflow/dags/ gs://$$TARGET_BUCKET/dags/
    id: deploy-dags
    entrypoint: bash
  - name: gcr.io/cloud-builders/gsutil
    args:
      - '-c'
      - |
        TARGET_BUCKET=$(cat /workspace/bucket_name.txt)
        gsutil -m rsync -r -d airflow/data/ gs://$$TARGET_BUCKET/data/
    id: deploy-data
    entrypoint: bash
options:
  logging: CLOUD_LOGGING_ONLY
substitutions:
  _ENV_NAME: demo-composer-dev
  _REGION: us-central1
  _AIRFLOW_VERSION: 2.10.5
  _IMAGE_VERSION: composer-3-airflow-2.10.5-build.24
  _SERVICE_ACCOUNT: 1031875039844-compute@developer.gserviceaccount.com
